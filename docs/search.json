[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Krish Suraparaju",
    "section": "",
    "text": "I’m an undergraduate at Carnegie Mellon University studying mathematics and computer science. I blog here about things I find interesting.\nMy favorite classes at CMU have been Theoretical Computer Science (15-251), Markov Chains (21-326) and Computational Biology (02-251).\n\n\nCarnegie Mellon University | Pittsburgh, PA | Aug 2022 - May 2026\nB.S. in Mathematics, Additional Major in Computer Science\n\n\n\nMeta | SWE Intern | May 2025 - Aug 2025\nAmazon | SDE Intern | May 2024 - Aug 2024\nCMU | Head TA for 15-122 | Aug 2023 - present\nMohimani Lab @ CMU | Undergraduate RA | Jan 2023 - Aug 2024"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Krish Suraparaju",
    "section": "",
    "text": "Carnegie Mellon University | Pittsburgh, PA | Aug 2022 - May 2026\nB.S. in Mathematics, Additional Major in Computer Science"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Krish Suraparaju",
    "section": "",
    "text": "Meta | SWE Intern | May 2025 - Aug 2025\nAmazon | SDE Intern | May 2024 - Aug 2024\nCMU | Head TA for 15-122 | Aug 2023 - present\nMohimani Lab @ CMU | Undergraduate RA | Jan 2023 - Aug 2024"
  },
  {
    "objectID": "posts/dual-numbers/index.html",
    "href": "posts/dual-numbers/index.html",
    "title": "Automatic Differentiation using Dual Numbers",
    "section": "",
    "text": "I recently came across a curious algebraic structure called the Dual Number system, denoted as \\(\\mathbb{R} (\\epsilon)\\). The dual numbers are an extension of the real numbers, with a very interesting property: evaluating a differentiable function \\(f\\) at a dual number \\(x\\) will give us both \\(f(x)\\) and \\(f'(x)\\) at the same time. This is a powerful idea in numerical analysis and machine learning, as it allows for efficient computation of derivatives."
  },
  {
    "objectID": "posts/dual-numbers/index.html#introduction",
    "href": "posts/dual-numbers/index.html#introduction",
    "title": "Automatic Differentiation using Dual Numbers",
    "section": "",
    "text": "I recently came across a curious algebraic structure called the Dual Number system, denoted as \\(\\mathbb{R} (\\epsilon)\\). The dual numbers are an extension of the real numbers, with a very interesting property: evaluating a differentiable function \\(f\\) at a dual number \\(x\\) will give us both \\(f(x)\\) and \\(f'(x)\\) at the same time. This is a powerful idea in numerical analysis and machine learning, as it allows for efficient computation of derivatives."
  },
  {
    "objectID": "posts/dual-numbers/index.html#dual-numbers",
    "href": "posts/dual-numbers/index.html#dual-numbers",
    "title": "Automatic Differentiation using Dual Numbers",
    "section": "Dual Numbers",
    "text": "Dual Numbers\nLet \\(\\epsilon \\neq 0\\) be a new “number” such that \\(\\epsilon^2 = 0\\) (Penn 2022). Before we go any further, we must first ask ourselves if such a number can even exist. The answer is of course not if you want to work in complete fields like \\(\\mathbb{R}\\) and \\(\\mathbb{C}\\). No matter how small a real (or complex) number is, as long as it is non-zero, its square will also be non-zero. So why do we care about this number then?\nOne reason is that it can help us model the notion of an “infinitesimal” from calculus, which can be thought of as a non-zero number that is “smaller” than any other number. Using the definition above then, we note that even though \\(\\epsilon\\) is non-zero, its square is zero, and so the number is somehow “smaller” than any other real (or complex) number. In order to study this more, let’s assume that such a number actually exists and try to see if any laws we know about \\(\\mathbb{R}\\) and \\(\\mathbb{C}\\) does (or does not) break down. Then, let’s see how it can be used to compute derivatives of a function.\nThe structure we want to study is defined as follows \\[\n\\mathbb{R} (\\epsilon) = \\{ a + b \\epsilon \\mid a, b \\in \\mathbb{R} \\}\n\\]"
  },
  {
    "objectID": "posts/dual-numbers/index.html#basic-arithmetic",
    "href": "posts/dual-numbers/index.html#basic-arithmetic",
    "title": "Automatic Differentiation using Dual Numbers",
    "section": "Basic Arithmetic",
    "text": "Basic Arithmetic\nFirst, let’s define how to add, subtract, and multiply. Given a dual number \\(x = a + b \\epsilon\\) and \\(y = c + d \\epsilon\\), define: \\[\\begin{align*}\nx + y &:= (a + c) + (b + d) \\epsilon \\\\\nx - y &:= (a - c) + (b - d) \\epsilon \\\\\nx \\cdot y &:= (a \\cdot c) + (a \\cdot d + d \\cdot c) \\epsilon \\\\\n\\end{align*}\\]\nWhenever we create new objects and define operations on the objects, we should always check that they are well defined. That means, for each operation above we need to check that if \\(x = y\\) and \\(z\\) is any other dual number then \\(x + z = y + z\\) and \\(x - z = y - z\\) and \\(x \\cdot z = y \\cdot z\\). In this case, checking this is very easy so I won’t do that. We can also divide \\(x / y\\), given that \\(c \\neq 0\\): \\[\n\\frac{x}{y} := \\frac{a}{c} + \\frac{b \\cdot c - a \\cdot d}{c^2}\n\\] Hopefully it is not hard to see that distributivity, associativity, and commutativity follow because we are simply using \\(+, -, \\cdot\\) from \\(\\mathbb{R}\\). This means all the nice properties we learned in high school about algebra on real numbers (ex. FOIL) still hold. So far so good.\nHowever, things get interesting when we starting playing with multiplication and division operator a bit more. Specifically, what happens when we multiply two numbers \\(0 + b \\epsilon\\) and \\(0 + d \\epsilon\\) where \\(b, d \\neq 0\\)? Clearly these are non-zero numbers. However, note that \\[\n(0 + b\\epsilon) + (0 + d\\epsilon) = (0 \\cdot 0) + (0 \\cdot d + b \\cdot 0)\\epsilon = 0\n\\] This s strange! Recall that in \\(\\mathbb{R}\\) and \\(\\mathbb{C}\\) there are no zero divisors. That is, if \\(a, b \\in \\mathbb{R} (\\text{or } \\mathbb{C})\\), and \\(a \\cdot b = 0\\) then either \\(a = 0\\) or \\(b = 0\\). We just saw that this need not be the case for dual numbers anymore! Finally, a place where dual number arithmetic breaks down. Nonetheless, it is still remarkable that most of the basic arithmetic operations and laws from \\(\\mathbb{R}\\) still hold, so let’s see what kind of algebra we can do on these numbers."
  },
  {
    "objectID": "posts/dual-numbers/index.html#polynomials",
    "href": "posts/dual-numbers/index.html#polynomials",
    "title": "Automatic Differentiation using Dual Numbers",
    "section": "Polynomials",
    "text": "Polynomials\nLet’s consider a simple polynomial function over the real numbers \\(f(x) = x^2\\). We can extend this function to accept dual numbers as input by replacing the real number \\(x = a\\) with the dual number \\(x = a + \\epsilon\\). \\[\nf((a + \\epsilon)) = (a+\\epsilon)\\cdot (a + \\epsilon) = a^2 + (a + a) \\epsilon = a^2 + 2 a \\epsilon\n\\] Notice what just happened. The term \\(2 a \\epsilon\\) is the derivative of the function \\(f\\) evaluated at \\(x = a\\). By just computing the function \\(f\\) at the modified dual number, we were able to get the derivative as well in one computation.\nLet’s use the Binomial Theorem to see if this generalizes to \\(f(a + \\epsilon) = (a+\\epsilon)^n\\) for an arbitrary \\(n\\): \\[\\begin{align*}\nf(a + \\epsilon) &= (a + \\epsilon)^n \\\\\n&= \\sum_{i = 0}^n {n \\choose i} a^{n - i} \\epsilon^i \\\\\n&= {n \\choose 0} a^n \\epsilon^0 + {n \\choose 1} a^{n-1} \\epsilon^1 + \\sum_{i = 2}^n {n \\choose i} a^{n - i} \\epsilon^i \\\\\n&= a^n + n \\cdot a^{n-1} \\epsilon\n\\end{align*}\\] Where the last step follows because \\(\\epsilon^2 = 0\\) (by definition) and so all the other terms with \\(\\epsilon^i\\) for \\(i \\geq 2\\) cancels out. Notice that this is exactly what we wanted to see: \\(f(a+\\epsilon) = f(a) + f'(a) \\epsilon\\)\nNow, lets go even futher and see if this notion generalizes to an arbitrary polynomial \\(f(a + \\epsilon) = p_n (a + \\epsilon)^n + p_{n-1} (a + \\epsilon)^{n-1} + \\cdots + p_1 (a + \\epsilon) + p_0\\): \\[\\begin{align*}\nf(a + \\epsilon) &= p_n (a + \\epsilon)^n + p_{n-1} (a + \\epsilon)^{n-1} + \\cdots + p_1 (a + \\epsilon) + p_0 \\\\\n&= p_n \\sum_{i = 0}^n {n \\choose i} a^{n - i} \\epsilon^i + p_{n-1} \\sum_{i = 0}^{n-1} {n-1 \\choose i} a^{n - 1- i} \\epsilon^i +p_1 (a + \\epsilon) + p_0  \\\\\n&= p_n (a^n + n ^{n-1} \\epsilon) + p_{n-1} (a^{n-1} + (n-1) a^{n-2} \\epsilon) + \\cdots + p_1 (a + \\epsilon) + p_0 \\\\\n&= p_n a^n + p_n n a^{n-1}\\epsilon + p_{n-1}a^{n-1} + p_{n-1} (n-1)a^{n-2}\\epsilon + \\cdots + p_1 a + p_1 \\epsilon + p_0 \\\\\n&= (p_n a^n + p_{n-1} a^{n-1} + \\cdots + p_1 a + p_0) +(p_n n a^{n-1} + p_{n-1} (n-1) a^{n-2} + \\cdots + p_1) \\epsilon \\\\\n&= f(a) + f'(a) \\epsilon\n\\end{align*}\\] and indeed it does."
  },
  {
    "objectID": "posts/dual-numbers/index.html#other-functions",
    "href": "posts/dual-numbers/index.html#other-functions",
    "title": "Automatic Differentiation using Dual Numbers",
    "section": "Other functions",
    "text": "Other functions\nMaybe we can actually make a stronger claim: does this property holds for all infinitely differentiable functions? So, let \\(f\\) be such a function evaluated at the dual number \\(a + c \\epsilon\\) (note that the coefficient for the dual part need not be 1 anymore). Then we can use the taylor series expansion of \\(f\\) to write \\[\\begin{align*}\nf(a + c\\epsilon) &= \\sum_{n = 0}^\\infty \\frac{f^{(n)} (a)}{n!} ((a + c\\epsilon) - a)^n \\\\\n&= \\sum_{n = 0}^\\infty \\frac{f^{(n)} (a)}{n!} (c\\epsilon)^n \\\\\n&= \\frac{f^{(0)} (a)}{0!} (c\\epsilon)^0 + \\frac{f^{(1)} (a)}{1!} (c\\epsilon)^1 + \\sum_{n = 2}^\\infty \\frac{f^{(n)} (a)}{n!} (c\\epsilon)^n \\\\\n& f(a) + f'(a) c \\epsilon\n\\end{align*}\\]\nand again, it does!\nBut what about composition of functions? Let \\(f, g\\) be functions extended to dual numbers such that \\(f(a + c \\epsilon) = f(a) + f'(a) c \\epsilon\\) and \\(g(a + c \\epsilon) = g(a) + g'(a) c \\epsilon\\). Then, note that: \\[\\begin{align*}\nf(g(a+\\epsilon)) &= f(g(a) + g'(a)\\epsilon) \\\\\n&= f(g(a)) + f'(g(a)) \\cdot g'(a) \\epsilon \\\\\n\\end{align*}\\] and notice that the dual component \\(f'(g(a)) \\cdot g'(a)\\) is exactly the chain rule of derivatives! So, now we can imagine all sorts of complicated functions like \\[\nf(x) = \\sin(e^{x^2 + 1})\n\\] and by using the dual number representation, we can compute both the function value and its derivative in a single forward pass through the function."
  },
  {
    "objectID": "posts/dual-numbers/index.html#closing-thoughts",
    "href": "posts/dual-numbers/index.html#closing-thoughts",
    "title": "Automatic Differentiation using Dual Numbers",
    "section": "Closing thoughts",
    "text": "Closing thoughts\nWhat I find most beautiful about dual numbers is how they transform the problem of differentiation from a difficult limiting process \\[\nf'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\n\\] into a problem of pure algebraic manipulation. This is incredibly beautiful because limits are (arguably) one of the ugliest tools in mathematics, and turning it into a formulation of abstract algebra is extremely satisfying.\nWhile we gained zero divisors in dual numbers, what we got in return makes up for it: a computational method for computing derivatives that is exact (no truncation error like finite differences) and efficient (requires roughly the same number of operations as computing \\(f\\) itself). This is why dual numbers, despite being a somewhat obscure mathematical structure, power automatic differentiation systems used in training neural networks."
  },
  {
    "objectID": "posts/bourgain-embedding/index.html",
    "href": "posts/bourgain-embedding/index.html",
    "title": "Metric Spaces, dimension reduction, and Bourgain Embeddings",
    "section": "",
    "text": "Metric embeddings and dimension reduction are important tools in computer science and mathematics for solving the curse of dimensionality. In this post, I want to examine the Bourgain embedding, which shows that any finite metric space can be embedded into an Euclidean metric space space with \\(O(\\log ⁡n)\\) distortion. While Bourgain embeddings are very impractical (the constant factors in the big - O are huge and the “reduced” dimensions is still high), it is an important result that shows us that no matter how “horrible” the initial metric space is, we can be achieve a distortion factor of \\(O(\\log n)\\).\nNote: I’ve written this post assuming that the reader has at least taken an undergraduate discrete math course. However, I will still define the important objects we will be using today.\n\n\nA metric space \\((X, d)\\) is a set \\(X\\) with a distance function \\(d: X \\times X \\to \\mathbb{R}\\). The distance function satisfies the following properties:\n\n\\(d(x, y) \\geq 0\\) for all \\(x, y \\in X\\)\n\\(d(x, y) = 0\\) if and only if \\(x = y\\)\n\\(d(x, y) = d(y, x)\\) for all \\(x, y \\in X\\)\n\\(d(x, y) \\leq d(x, z) + d(z, y)\\) for all \\(x, y, z \\in X\\)\n\nSome examples of metric spaces:\n\nA weighted graph \\(G = (V, E)\\) with \\(X = V\\) and \\(d(x, y) =\\) length of the shortest path between \\(x\\) and \\(y\\).\nThe DNA space with \\(X = \\{A, C, G, T\\}^n\\) and \\(d(x, y) =\\) number of positions where \\(x\\) and \\(y\\) differ.\nThe Euclidean space \\(\\mathbb{R}^n\\) with \\(X = \\mathbb{R}^n\\) and \\(d(x, y) = \\|x - y\\|_2 = \\sqrt{(x_1 - y_1)^2 + \\cdots + (x_n - y_n)^2}\\).\n\n\n\n\nA map \\(f: X \\to Y\\) between two metric spaces \\((X, d_X)\\) and \\((Y, d_Y)\\) is called an embedding that maps elements of \\(X\\) to elements of \\(Y\\).\nThe embedding is said to be distance-preserving (isometric) if \\(d_Y(f(x), f(y)) = d_X(x, y)\\) for all \\(x, y \\in X\\). However, very rarely do we have distance-preserving embeddings between metric spaces. Instead, we often consider embeddings that are “almost” distance-preserving.\nAn embedding with distortion of \\(\\alpha\\) of a metric space \\((X, d_X)\\) into another metric space \\((Y, d_Y)\\) is a map \\(f: X \\to Y\\) such that there exists constant \\(r &gt; 0\\) for which \\[r \\cdot d_X(x, y) \\leq d_Y(f(x), f(y)) \\leq \\alpha r \\cdot d_X(x, y) \\text{ for all } x, y \\in X\\] The distortion of an embedding is the smallest \\(\\alpha\\) for which such a map exists.\nBecause we are working in a finite set for now, we can equivalently define the distortion in terms of the contraction and expansion. Given a map \\(f: X \\to Y\\), let:\n\\[\\text{Contraction}(f) = \\max_{x, y \\in X} \\frac{d_Y(f(x), f(y))}{d_X(x, y)}\\]\n\\[ \\text{Expansion}(f) = \\max_{x, y \\in X} \\frac{d_X(x, y)}{d_Y(f(x), f(y))}\\]\nDefine the distortion of \\(f\\) as \\(\\alpha = \\text{Expansion}(f)\\cdot\\text{Contraction}(f)\\)."
  },
  {
    "objectID": "posts/bourgain-embedding/index.html#introduction",
    "href": "posts/bourgain-embedding/index.html#introduction",
    "title": "Metric Spaces, dimension reduction, and Bourgain Embeddings",
    "section": "",
    "text": "Metric embeddings and dimension reduction are important tools in computer science and mathematics for solving the curse of dimensionality. In this post, I want to examine the Bourgain embedding, which shows that any finite metric space can be embedded into an Euclidean metric space space with \\(O(\\log ⁡n)\\) distortion. While Bourgain embeddings are very impractical (the constant factors in the big - O are huge and the “reduced” dimensions is still high), it is an important result that shows us that no matter how “horrible” the initial metric space is, we can be achieve a distortion factor of \\(O(\\log n)\\).\nNote: I’ve written this post assuming that the reader has at least taken an undergraduate discrete math course. However, I will still define the important objects we will be using today.\n\n\nA metric space \\((X, d)\\) is a set \\(X\\) with a distance function \\(d: X \\times X \\to \\mathbb{R}\\). The distance function satisfies the following properties:\n\n\\(d(x, y) \\geq 0\\) for all \\(x, y \\in X\\)\n\\(d(x, y) = 0\\) if and only if \\(x = y\\)\n\\(d(x, y) = d(y, x)\\) for all \\(x, y \\in X\\)\n\\(d(x, y) \\leq d(x, z) + d(z, y)\\) for all \\(x, y, z \\in X\\)\n\nSome examples of metric spaces:\n\nA weighted graph \\(G = (V, E)\\) with \\(X = V\\) and \\(d(x, y) =\\) length of the shortest path between \\(x\\) and \\(y\\).\nThe DNA space with \\(X = \\{A, C, G, T\\}^n\\) and \\(d(x, y) =\\) number of positions where \\(x\\) and \\(y\\) differ.\nThe Euclidean space \\(\\mathbb{R}^n\\) with \\(X = \\mathbb{R}^n\\) and \\(d(x, y) = \\|x - y\\|_2 = \\sqrt{(x_1 - y_1)^2 + \\cdots + (x_n - y_n)^2}\\).\n\n\n\n\nA map \\(f: X \\to Y\\) between two metric spaces \\((X, d_X)\\) and \\((Y, d_Y)\\) is called an embedding that maps elements of \\(X\\) to elements of \\(Y\\).\nThe embedding is said to be distance-preserving (isometric) if \\(d_Y(f(x), f(y)) = d_X(x, y)\\) for all \\(x, y \\in X\\). However, very rarely do we have distance-preserving embeddings between metric spaces. Instead, we often consider embeddings that are “almost” distance-preserving.\nAn embedding with distortion of \\(\\alpha\\) of a metric space \\((X, d_X)\\) into another metric space \\((Y, d_Y)\\) is a map \\(f: X \\to Y\\) such that there exists constant \\(r &gt; 0\\) for which \\[r \\cdot d_X(x, y) \\leq d_Y(f(x), f(y)) \\leq \\alpha r \\cdot d_X(x, y) \\text{ for all } x, y \\in X\\] The distortion of an embedding is the smallest \\(\\alpha\\) for which such a map exists.\nBecause we are working in a finite set for now, we can equivalently define the distortion in terms of the contraction and expansion. Given a map \\(f: X \\to Y\\), let:\n\\[\\text{Contraction}(f) = \\max_{x, y \\in X} \\frac{d_Y(f(x), f(y))}{d_X(x, y)}\\]\n\\[ \\text{Expansion}(f) = \\max_{x, y \\in X} \\frac{d_X(x, y)}{d_Y(f(x), f(y))}\\]\nDefine the distortion of \\(f\\) as \\(\\alpha = \\text{Expansion}(f)\\cdot\\text{Contraction}(f)\\)."
  },
  {
    "objectID": "posts/bourgain-embedding/index.html#bourgain-embedding",
    "href": "posts/bourgain-embedding/index.html#bourgain-embedding",
    "title": "Metric Spaces, dimension reduction, and Bourgain Embeddings",
    "section": "Bourgain Embedding",
    "text": "Bourgain Embedding\nGiven an arbitrary finite metric space \\((X, d)\\) with \\(n\\) points, Bourgain’s theorem says that there exists a map \\(f: X \\to \\mathbb{R}^k\\) such that the distortion of \\(f\\) is \\(\\alpha \\in O(\\log n)\\), and \\(k \\in O(\\log^2 n)\\). The proof of this theorem is beyond the scope of this post, but it is a constructive proof so there is a natural algorithm that arises from the proof which we can implement.\nThe Bourgain embedding algorithm is as follows (Ye 2023):\n\nLet \\(c\\) be a sufficiently large constant, and let \\(\\log(n)\\) denote the base-2 logarithm of \\(n\\).\nFor each point \\(x \\in X\\), define its embedding vector \\(f(x)\\) in the following steps:\n\nFor \\(i \\in \\{1, 2, \\dots, \\lceil \\log_2(n) \\rceil \\}\\):\n\nFor \\(j \\in \\{1, 2, \\dots, c \\cdot \\lceil \\log_2(n) \\rceil \\}\\):\n\nChoose a random subset \\(S_{ij} \\subseteq X\\), where each \\(y \\in X\\) is included in \\(S_{ij}\\) with probability \\(2^{-i}\\).\nCompute \\(d(x, S_{ij})\\), the minimum distance from \\(x\\) to any point in \\(S_{ij}\\).\n\nConstruct the embedding vector: \\(f(x) = \\langle d(x, S_{11}), d(x, S_{12}), \\dots, d(x, S_{\\lceil \\log_2(n) \\rceil \\cdot c \\cdot \\lceil \\log_2(n) \\rceil})\\rangle.\\)\n\n\n\nAn intuition for the algorithm is that it creates a “fingerprint” for each point by measuring its distance to random subsets of the space at multiple scales. So, for each point, we answer the question:\n\n“How far am I from a randomly chosen half of all points?”\n“How far am I from a randomly chosen quarter of all points?”\n“How far am I from a randomly chosen eighth of all points?”\n…\n\nWhy does this capture distance information? Imagine two points \\(x\\) and \\(y\\) in our original metric space. If they are close, they’ll have similar distances to most random subsets. When we sample a random subset \\(S\\), chances are the nearest point in \\(S\\) to \\(x\\) will also be close to \\(y\\) so, the embedded distances will also be similar.\nHowever, if \\(x\\) and \\(y\\) are far apart, then at some scale, we’ll sample points that “separate” them. That is, there will be random subsets where \\(x\\) is close to some sampled point but \\(y\\) is far from all sampled points (or vice versa). This creates a difference in their fingerprints that the algorithm can capture when construction the embedding.\nNote that in practice, this algorithm can be really bad because of the big-O constants. For example, if \\(X = \\mathbb{R}^{1000}\\), and we chose \\(c = 100\\) (for less distortion), then the reduced dimension \\(k = 100 \\cdot \\log^2{1000} = 900\\). This is an improvement over the \\(1000\\) dimensional space, but just barely."
  },
  {
    "objectID": "posts/bourgain-embedding/index.html#implementation",
    "href": "posts/bourgain-embedding/index.html#implementation",
    "title": "Metric Spaces, dimension reduction, and Bourgain Embeddings",
    "section": "Implementation",
    "text": "Implementation\nLet’s implement this in python using numpy so we can vectorize parts of the code.\n\nimport numpy as np\n\ndef bourgain_embedding(dist_mat, c=10):\n    n = len(dist_mat)\n\n    if n &lt;= 1:\n        return np.zeros((n, 1))\n\n    log_n = int(np.ceil(np.log2(n)))\n    k = c * log_n * log_n\n    max_dist = dist_mat.max()\n\n    f_x = np.zeros((n, k))\n\n    j = 0\n    for i in range(1, log_n + 1):\n        p = 2 ** (-i)\n        for _ in range(c * log_n):\n            subset_mask = np.random.rand(n) &lt; p\n\n            if not np.any(subset_mask):\n                f_x[:, j] = max_dist\n            else:\n                f_x[:, j] = dist_mat[:, subset_mask].min(axis=1)\n            j += 1\n\n    return f_x\n\nWe can plot the distortion of this algorithm on a randomly generated metric space, as a function of \\(n\\) to see the logarithmic curve.\n\n\nCode\nimport matplotlib.pyplot as plt\n\ndef distortion(dist_mat, emb):\n    n = dist_mat.shape[0]\n    max_expand = 0.0\n    max_contract = 0.0\n\n    for i in range(n):\n        for j in range(i + 1, n):\n            d0 = dist_mat[i, j]\n            d1 = np.linalg.norm(emb[i] - emb[j], ord=1)\n\n            if d0 &gt; 0 and d1 &gt; 0:\n                max_expand = max(max_expand, d1 / d0)\n                max_contract = max(max_contract, d0 / d1)\n\n    return max_expand * max_contract\n\ndef gen_random_space(n, d=5, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    X = np.random.randn(n, d)\n    diff = X[:, None, :] - X[None, :, :]\n    return np.linalg.norm(diff, axis=2)\n\nc_fixed = 8\nns = [10, 50, 100, 350, 500, 750, 1000]\n\ndistortions = []\nfor n in ns:\n    dist_mat = gen_random_space(n, d=5, seed=0)\n    emb = bourgain_embedding(dist_mat, c=c_fixed)\n    distortions.append(distortion(dist_mat, emb))\n\nlog_ns = np.log(ns)\nlog_ns_scaled = log_ns / log_ns[0] * distortions[0]\n\nplt.figure(figsize=(7, 5))\nplt.plot(ns, distortions, marker='o', label=\"Bourgain distortion\")\nplt.plot(ns, log_ns_scaled, linestyle='--', label=r\"scaled $\\log n$\")\n\nplt.xlabel(r\"$n$\")\nplt.ylabel(\"Distortion\")\nplt.title(\"Bourgain embedding distortion vs log n\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nNote that the variable \\(c\\) is a hyper-parameter to this algorithm, and we can observe distortion as a function of \\(c\\) as well.\n\n\nCode\nn_fixed = 100\ncs = [10, 50, 100, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300]\n\ndistortions = []\nfor c in cs:\n    dist_mat = gen_random_space(n_fixed, d=5, seed=0)\n    emb = bourgain_embedding(dist_mat, c=c)\n    distortions.append(distortion(dist_mat, emb))\n\n\nplt.figure(figsize=(7, 5))\nplt.plot(cs, distortions, marker='o', label=\"Bourgain distortion\")\n\nplt.xlabel(r\"$c$\")\nplt.ylabel(\"Distortion\")\nplt.title(\"Bourgain embedding distortion vs c\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/noisy-channels/index.html",
    "href": "posts/noisy-channels/index.html",
    "title": "Sending Messages over Noisy Channels",
    "section": "",
    "text": "A fundamental problem in electrical engineering is sending messages over noisy channels. For example, all messages sent over the internet have to eventually be transmitted over physical channels (copper wires or fiber optic cables), and these channels can be damaged by the elements (eg. sharks)\nI recently came across a method to reduce this problem to a purely mathematical one: the sphere packing problem, which aims to find the densest packing of non-overlapping \\(n\\) dimensional spheres in a given space."
  },
  {
    "objectID": "posts/noisy-channels/index.html#introduction",
    "href": "posts/noisy-channels/index.html#introduction",
    "title": "Sending Messages over Noisy Channels",
    "section": "",
    "text": "A fundamental problem in electrical engineering is sending messages over noisy channels. For example, all messages sent over the internet have to eventually be transmitted over physical channels (copper wires or fiber optic cables), and these channels can be damaged by the elements (eg. sharks)\nI recently came across a method to reduce this problem to a purely mathematical one: the sphere packing problem, which aims to find the densest packing of non-overlapping \\(n\\) dimensional spheres in a given space."
  },
  {
    "objectID": "posts/noisy-channels/index.html#signals-and-code",
    "href": "posts/noisy-channels/index.html#signals-and-code",
    "title": "Sending Messages over Noisy Channels",
    "section": "Signals and Code",
    "text": "Signals and Code\nBut first, let’s define the noisy channel problem more formally. Let \\(T &gt; 0\\) be a fixed length of time corresponding to the length of a signal transmission.\nA signal is a continuous function \\(s : [0, T] \\to \\mathbb{R},\\) where \\(s(t)\\) is the amplitude of the signal at time \\(t\\), and the frequencies do not surpass some fixed limit \\(W\\). Think of \\(s(t)\\) as the voltage of the signal at time \\(t\\) (for copper wires), or the intensity of a light signal at time \\(t\\) (for fiber optic cables).\nA code is a finite set of signals \\(\\{s_1, s_2, \\ldots, s_n\\}.\\) This can be thought of as a symbolic alphabet for two computers to communicate over a channel. A simple example of a code is \\[\n\\{ s_1(t) = 1,\\; s_2(t) = -1 \\},\n\\] which can be used to send binary messages over a channel.\nThe Shannon–Nyquist Sampling Theorem states that any signal \\(s(t)\\) with frequencies less than \\(W\\) can be uniquely represented by a finite set of samples \\[\n\\left\\{ s(0), s\\!\\left(\\tfrac{1}{W}\\right), s\\!\\left(\\tfrac{1}{2W}\\right), \\ldots, s\\!\\left(\\tfrac{n-1}{2W}\\right) \\right\\},\n\\] where \\(n = 2WT\\). This means that we can represent any signal \\(s(t)\\) as a vector \\(\\vec{s} \\in \\mathbb{R}^n,\\) and any code as a finite subset \\(C \\subseteq \\mathbb{R}^n\\), where each element of \\(C\\) represents a signal.\n\n\n\n\n\nThe continuous signal above \\(S(t)\\) represented by the discrete samples \\(S_i\\). Therefore, we will represent a signal as a vector in the remaining discussion."
  },
  {
    "objectID": "posts/noisy-channels/index.html#the-noisy-channel",
    "href": "posts/noisy-channels/index.html#the-noisy-channel",
    "title": "Sending Messages over Noisy Channels",
    "section": "The Noisy Channel",
    "text": "The Noisy Channel\nIn the real world, the sent signal \\(\\vec{s}\\) is almost never the same as the received signal \\(\\vec{r}\\). This is because the channel introduces noise, which we model as a random perturbation in the input.\nFormally, we assume that the received signal is \\[\n\\vec{r} = \\vec{s} + \\vec{z},\n\\] where \\(\\vec{z}\\) is a random vector with Gaussian entries (each \\(z_i \\sim \\mathcal{N}(0, \\sigma^2)\\) and is i.i.d). If the receiver wants to determine which signal was sent, a natural decoding strategy is nearest-neighbor decoding: \\[\n\\hat{\\vec{s}} = \\underset{\\vec{s_i} \\in C}{\\text{argmin}} \\| \\vec{r} - \\vec{s_i} \\|_2.\n\\]\nHowever, if two signals in the code are too close together, noise may make decoding ambiguous. For example, in the following situation:\n\n\n\n\n\nwhich signal does \\(\\vec{r}\\) correspond to? Both \\(\\vec{s_1}\\) and \\(\\vec{s_2}\\) are equally likely.\n\n\nTo solve this problem, remember that we assumed \\(\\vec{r} = \\vec{s} + \\vec{z}\\) and that each \\(z_i \\sim \\mathcal{N}(0, \\sigma^2)\\). A fundamental property of the Gaussian distribution is that \\[\n\\mathbb{P}[-3 \\sigma \\leq z_i \\leq 3 \\sigma] \\approx 99.7\\%\n\\] So, we can use this to figure out a bound on the distance between \\(\\vec{r}\\) and \\(\\vec{s}\\) with high probability. In the worst-case, each component is such that \\(|z_i| = 3 \\sigma\\). Since we have \\(n\\) components, this means that \\[\\begin{align*}\n\\| \\vec{r} - \\vec{s} \\|_2 =  \\| \\vec{z}\\|_2 &= \\sqrt{\\sum_{i = 1}^{n} z_i^2} \\\\ &\\leq\\sqrt{\\sum_{i = 1}^{n} (3 \\sigma)^2} \\\\ &\\leq \\sqrt{n \\cdot 9 \\sigma^2} \\\\ &\\leq 3 \\sigma \\sqrt{n}\n\\end{align*}\\] with probability \\(99.7\\%\\). This means that the worst-case noise can push the received signal \\(\\vec{r}\\) up to a distance of \\(3 \\sigma \\sqrt{n}\\) away from the true signal \\(\\vec{s}\\). This creates a sphere of radius \\(3 \\sigma \\sqrt{n}\\) around \\(\\vec{s_1}\\). To make our decoding as unambiguous as possible, we need to ensure that even when noise pushes \\(\\vec{r}\\) to the edge of this sphere, it is still closer to \\(\\vec{s}\\) than any other signal \\(\\vec{s_2} \\in C\\). But signal \\(\\vec{s_2}\\) also has a sphere of radius \\(3 \\sigma \\sqrt{n}\\) around it. Therefore, to guarantee that two spheres don’t overlap, the minimum distance between any two signals must be at least \\(6 \\sigma \\sqrt{n}\\)"
  },
  {
    "objectID": "posts/noisy-channels/index.html#dense-sphere-packing",
    "href": "posts/noisy-channels/index.html#dense-sphere-packing",
    "title": "Sending Messages over Noisy Channels",
    "section": "Dense Sphere packing",
    "text": "Dense Sphere packing\nNow, you might ask: why don’t we just pick signals that are as far apart as possible? For example, we could place just two signals at opposite ends of our signal space.\nBut recall that a signal \\(\\vec{s}\\) represents the amplitude or voltage of a message over time. Physicists have told us the power of a signal is proportional to the square of its amplitude: \\[\n\\text{Power} \\propto \\|\\vec{s}\\|_2^2 = \\sum_{i=1}^{n} s_i^2\n\\]\nIn practice, we cannot transmit signals with arbitrarily large power. There are physical limits on how much voltage we can apply to a copper wire and how much light we can send through a fiber optic cable. If we set a maximum power budget \\(P\\), then all our signals must satisfy \\[\n\\|\\vec{s}\\|_2^2 \\leq nP \\quad \\Longrightarrow \\quad \\|\\vec{s}\\|_2 \\leq \\sqrt{nP}\n\\]\nThis means all our signals must lie within a sphere of radius \\(\\sqrt{nP}\\) in \\(\\mathbb{R}^n\\), which is a compact region. The more signals we can fit in this region, the more information we can transmit per signal. For example, a code with 2 signals transmits only 1 bit per transmission, but a code with 256 signals transmits 8 bits per transmission.\nAt the same time, each signal needs a sphere of radius \\(3\\sigma\\sqrt{n}\\) around it to ensure correct decoding with probability \\(99.7\\%\\). This is exactly the sphere packing problem: what is the maximum number of non-overlapping spheres of radius \\(3\\sigma\\sqrt{n}\\) that we can pack inside a sphere of radius \\(\\sqrt{nP}\\)? Each sphere center represents a signal in our code, and finding the densest packing directly gives us the code that can transmit the most information reliably. Therefore, the problem of designing optimal codes for noisy channels reduces to an entirely abstract problem in math."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "As each new author finds cleverer proofs or treatments of a theory, the treatment evolves towards the one that contains the ‘shortest proofs’. Unfortunately, these are often in a form that causes the new student to ponder ‘How did anyone think this?’ By going back to the original sources, one can usually see the subject evolving naturally.” — Peter Sarnak\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlgorithms for Sampling from a probability distribution\n\n\n\nmath\n\ncs\n\n\n\n\n\n\n\n\n\nOct 8, 2025\n\n\nKrish Suraparaju\n\n\n\n\n\n\n\n\n\n\n\n\nAutomatic Differentiation using Dual Numbers\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nApr 8, 2025\n\n\nKrish Suraparaju\n\n\n\n\n\n\n\n\n\n\n\n\nSending Messages over Noisy Channels\n\n\n\nmath\n\nece\n\n\n\n\n\n\n\n\n\nDec 25, 2024\n\n\nKrish Suraparaju\n\n\n\n\n\n\n\n\n\n\n\n\nMetric Spaces, dimension reduction, and Bourgain Embeddings\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nDec 20, 2024\n\n\nKrish Suraparaju\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/sampling/index.html",
    "href": "posts/sampling/index.html",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "",
    "text": "Drawing samples from a probability distribution \\(\\pi\\) is a problem that arises often in computer science. For example in generative AI, language models sample tokens from learned probability distributions to generate new text. In computer graphics, many graphical engines randomly sample light paths bouncing around to simulate realistic lighting. But what exactly does it mean for a computer or an algorithm to sample from a probability distribution? How can a deterministic machine like a modern computer sample “randomly” from a distribution?"
  },
  {
    "objectID": "posts/sampling/index.html#introduction",
    "href": "posts/sampling/index.html#introduction",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "",
    "text": "Drawing samples from a probability distribution \\(\\pi\\) is a problem that arises often in computer science. For example in generative AI, language models sample tokens from learned probability distributions to generate new text. In computer graphics, many graphical engines randomly sample light paths bouncing around to simulate realistic lighting. But what exactly does it mean for a computer or an algorithm to sample from a probability distribution? How can a deterministic machine like a modern computer sample “randomly” from a distribution?"
  },
  {
    "objectID": "posts/sampling/index.html#the-uniform-distribution",
    "href": "posts/sampling/index.html#the-uniform-distribution",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "The Uniform Distribution",
    "text": "The Uniform Distribution\nLet’s start the discussion by coming up with algorithms for sampling integers uniformly randomly in a fixed range.\n\nInteger in range \\([0, 2^N]\\)\nFirst, let’s see if we can generate a uniformly random integer \\(M \\in \\{0, \\cdots, 2^N - 1\\}\\). That is, we want to come up with an algorithm to produce \\(M\\) such that \\[\\mathbb{P}[M = m] = \\frac{1}{2^N}\\] for all \\(m \\in \\{0, \\cdots, 2^N - 1\\}\\).\nWell, given that we only have a random bit generator, there is really only one thing we can do here. We should generate \\(N\\) independent bits using our random bit generator and concatenate them together to get the base 2 representation of the integer we return.\n\nAlgorithm 1\n\\(M \\gets 0\\)\nfor \\(i = 1\\) to \\(N\\) do\n\\(\\quad M \\gets M + B_i \\cdot 2^i\\)\nreturn \\(M\\)\n\nLet’s check that this gives us the desired result. Let \\(B_1, B_2, \\dots, B_N\\) be the bits we generated. Now, note that for any integer \\(k \\in \\{0, \\cdots, 2^N - 1\\}\\), there exists a unique binary representation: \\[\nk = \\sum_{i = 1}^{N} b_i \\cdot 2^i\n\\] where each \\(b_i \\in \\{0, 1\\}\\) is the \\(i\\)-th bit of \\(k\\). The probability that \\(M = k\\) is given as: \\[\\begin{align*}\n\\mathbb{P}[M = k] &= \\mathbb{P}[B_0 = b_0, B_1 = b_1, \\cdots, B_n = b_n] \\\\\n&= \\mathbb{P}[B_0 = b_0] \\cdot \\mathbb{P}[B_1 = b_1] \\cdots \\mathbb{P}[B_N = b_n] \\tag{By independence} \\\\\n&= \\frac{1}{2} \\cdot \\frac{1}{2} \\cdots \\frac{1}{2} \\tag{$N$ times} \\\\\n&= \\frac{1}{2^N}\n\\end{align*}\\] as desired.\n\n\nInteger in Arbitrary Range\nGreat, now lets move onto a slightly more difficult problem: generating a uniformly random integer in \\(\\{0, \\dots, M\\}\\), where \\(M\\) is not necessarily a power of \\(2\\).\nA first idea would be to use the same approach as before and concatenate a string of \\(N\\) random bits. This, however, does not work. For example, if \\(N = 3\\) and \\(M = 4\\) then our random bit generator produces outcomes in the range \\(\\{0, \\dots, 2^3 - 1\\} = \\{0, 1, 2, 3, 4, 5, 6, 7\\}\\). Each of these \\(8\\) outcomes occurs with probability \\(\\frac{1}{8}\\). However, we wanted an integer in the range \\(\\{0, 1, 2, 3, 4\\}\\), and the probability of each outcome to be exactly \\(\\frac{1}{5}\\).\nAnother approach would be to generate \\(N\\) random bits as before, and then return \\(N \\mod (M + 1)\\). I leave it as an exercise to figure out why this approach also does not work (Hint: use the same counter example from above).\nNotice that the issue in the above two approach is that our algorithm considers values that are outside the given range. To fix this problem, one idea would be to simply ignore an integers that are outside the range. More formally, define the algorithm as\n\nAlgorithm 2\n\\(P \\gets \\lceil \\log_2 (M + 1) \\rceil\\)\nrepeat\n\\(\\quad\\) Generate \\(N \\in \\{0, \\cdots, 2^P - 1\\}\\) using Algorithm 1\nuntil \\(N \\leq M\\)\nreturn \\(N\\)\n\nThis algorithm is called rejection sampling. A subtle difference between this algorithm and the previous algorithm is that its running time is non-deterministic. For example, we know that algorithm 1 terminates after generating \\(N\\) random bits. Algorithm 2, however, has no such guarantees. It is technically possible that we get really really really unlucky and always generate \\(N &gt; M\\) and so the algorithm would never return a number.\nSo, let’s compute probability that the algorithm terminates, which only happens when \\(N \\leq M\\) \\[\\begin{align*}\n\\mathbb{P}[N \\leq M] &= \\sum_{i \\leq M} \\mathbb{P}[N = i] \\tag{CDF of $N$} \\\\\n&= \\sum_{i = 0}^M \\frac{1}{2^N} \\tag{From Algorithm 1} \\\\\n&= \\frac{(M + 1)}{2^N}\n\\end{align*}\\]\nNote that if \\(M \\ll N\\) then the exponential in the denominator dominates, and the probability of terminating is near zero. When \\(M \\gg N\\) then the fraction is approximately linear, and so the algorithm terminates with higher probability.\nHowever, in the case that the algorithm does return, then we can be sure that it is correct. We prove this below. Note that for any \\(k \\in \\{0, \\cdots, M\\}\\), we have \\[\\begin{align*}\n\\mathbb{P}[N = k] &= \\mathbb{P}[N = k | N \\leq M] \\tag{Since $N \\leq M$ iff $N$ is returned} \\\\\n&= \\frac{\\mathbb{P}[N = k, N \\leq M]}{\\mathbb{P}[N \\leq M]} \\tag{Definition of conditional prob.} \\\\\n&= \\frac{\\mathbb{P}[N = k]}{\\mathbb{P}[N \\leq M]} \\tag{$k \\leq M$ so if $N = k$, we know $N \\leq M$} \\\\\n&= \\frac{1/2^N}{(M+1)/2^N} \\\\\n&= \\frac{1}{M + 1}\n\\end{align*}\\] as desired.\n\n\nReal number in range \\([0, 1]\\)\nNow let’s move onto the hardest problem yet: sampling a real number in the range \\([0, 1]\\). Note that every real number \\(r \\in [0, 1]\\) can be represented as a binary expansion: \\[\nr = \\sum_{i=1}^{\\infty} \\frac{B_i}{2^i} = 0.B_1B_2B_3\\dots\n\\] where each \\(B_i \\in \\{0, 1\\}\\). Again, our first instinct should be to ask if generating an infinite string of bits and concatenating them gives us the desired result. In this case, it turns out to be true. However, the proof of this fact is non-trivial and takes quite a lot of work.\n\n\n\n\n\n\nImportantMain Claim\n\n\n\nIf \\(B_1, B_2, B_3, \\dots\\) are independent uniform random bits, then \\[\nU = \\sum_{i=1}^{\\infty} \\frac{B_i}{2^i}\n\\] is uniformly distributed on \\([0, 1]\\).\n\n\nTo prove this, we need to show that for any interval \\([a, b) \\subseteq [0, 1]\\), we have \\[\n\\mathbb{P}[U \\in [a, b)] = \\text{length}([a, b)]) = b - a\n\\]\n\nPartitioning \\([0, 1]\\) and characterizing the partitions\nThe proof uses a clever partitioning argument. We’ll divide \\([0, 1]\\) into dyadic intervals, which are defined to be intervals whose endpoints are fractions with powers of 2 in the denominator.\nFor any arbitrary \\(k \\in \\mathbb{N}\\), we can partition \\([0, 1]\\) into \\(2^k\\) equal intervals: \\[\nI_j = \\left[\\frac{j}{2^k}, \\frac{j+1}{2^k}\\right) \\quad \\text{for } j = 0, 1, \\dots, 2^k - 1\n\\]\nEach interval has length \\(\\frac{1}{2^k}\\), and together they cover the entire unit interval. The larger \\(k\\), the better this approximation gets.\nNow, I claim that the first \\(k\\) bits \\((B_1, \\dots, B_k)\\) of \\(U\\) completely determine which dyadic interval \\(I_j\\) contains the value \\(U\\). Specifically: \\[\nU \\in I_j = \\left[\\frac{j}{2^k}, \\frac{j+1}{2^k}\\right) \\iff \\sum_{i=1}^{k} \\frac{B_i}{2^{i}} = \\frac{j}{2^k}\n\\]\nTo see why, we can decompose \\(U\\) into two parts:\n\\[\nU = \\underbrace{\\sum_{i=1}^{k} \\frac{B_i}{2^i}}_{:=U_k} + \\underbrace{\\sum_{i=k+1}^{\\infty}\\frac{B_i}{2^i}}_{:=R_k}\n\\] where \\(U_k\\) represents the first \\(k\\) bits and \\(R_k\\) represents the remaining bits. Now, note that The first \\(k\\) bits can only produce discrete values because there are \\(2^k\\) possible bit strings of length \\(k\\), and these values are \\[\\left\\{0, \\frac{1}{2^k}, \\frac{2}{2^k}, \\ldots, \\frac{2^k-1}{2^k}\\right\\}\\] Observe that these are exactly the left endpoints of our dyadic intervals \\(I_j\\).\nNow, The remaining bits \\(R_k\\) can be rewritten by factoring out \\(\\frac{1}{2^k}\\): \\[\\begin{align*}\nR_k &= \\sum_{i=k+1}^{\\infty} \\frac{B_i}{2^i} = \\frac{1}{2^k} \\sum_{i=1}^{\\infty} \\frac{B_{k+i}}{2^i}\n\\end{align*}\\] Since \\(\\sum_{i=1}^{\\infty} \\frac{B_{k+i}}{2^i}\\) is a binary expansion taking values in \\([0, 1)\\), we have \\[0 \\leq R_k &lt; \\frac{1}{2^k}\\] So, we have that \\(R_k\\) is strictly less than the width of a dyadic interval.\nTherefore, we can now claim that if \\(U_k = \\frac{j}{2^k}\\), then \\(U = \\frac{j}{2^k} + R_k\\) must satisfy \\[\\frac{j}{2^k} \\leq U &lt; \\frac{j+1}{2^k}\\] placing \\(U\\) in interval \\(I_j\\). Conversely, if \\(U \\in I_j\\), the constraint \\[\\frac{j}{2^k} \\leq U &lt; \\frac{j+1}{2^k}\\] combined with the fact that \\(U_k\\) is a discrete value in this range forces \\(U_k = \\frac{j}{2^k}\\). Therefore, we have shown that\n\n\n\n\n\n\n\\[\nU \\in I_j \\iff \\sum_{i = 1}^k \\frac{B_i}{2^i} = \\frac{j}{2^k}\n\\]\n\n\n\n\n\nProbability of landing in \\(I_j\\)\nNow we can calculate the probability that \\(U\\) lands in a specific dyadic interval \\(I_j\\):\n\\[\\begin{align*}\n\\mathbb{P}[U \\in I_j] &= \\mathbb{P}\\left[\\sum_{i=1}^{k} \\frac{B_i}{2^{i}} = \\frac{j}{2^k}\\right] \\\\\n&= \\mathbb{P}[B_1 = b_1, B_2 = b_2, \\dots, B_k = b_k]\n\\end{align*}\\]\nwhere \\((b_1, \\dots, b_k)\\) is the binary representation of \\(j\\).\nSince the bits are independent and each has probability \\(\\frac{1}{2}\\):\n\\[\\begin{align*}\n\\mathbb{P}[U \\in I_j] &= \\prod_{i=1}^{k} \\mathbb{P}[B_i = b_i] \\\\\n&= \\prod_{i=1}^{k} \\frac{1}{2} \\\\\n&= \\frac{1}{2^k}\n\\end{align*}\\]\nNote that this is exactly the length of the interval \\(I_j\\)! Therefore, we have show that at least for dyadic intervals, \\(U\\) is uniformly distributed!\n\n\nExtending to General Intervals\n\n\n\n\n\n\nNoteTechnical Note\n\n\n\n\n\nExtending this to the general interval \\([a, b]\\) is complicated and requires careful machinery taught usually in a course in real analysis. Therefore, will handwave a lot of the technicalities, but do keep in mind that there is more careful argument to be made here.\n\n\n\nFor a general interval \\([a, b) \\subseteq [0, 1]\\), we approximate it using dyadic intervals. Let \\(J_k\\) be the set of indices where \\(I_j \\subseteq [a, b)\\). Then:\n\\[\n[a, b) \\approx \\bigcup_{j \\in J_k} I_j\n\\]\nAs \\(k\\) increases, the dyadic intervals become finer, and this approximation improves.\nSince the dyadic intervals are disjoint:\n\\[\\begin{align*}\n\\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] &= \\sum_{j \\in J_k} \\mathbb{P}[U \\in I_j] \\\\\n&= \\sum_{j \\in J_k} \\frac{1}{2^k} \\\\\n&= \\frac{|J_k|}{2^k}\n\\end{align*}\\]\nwhere \\(|J_k|\\) is the number of dyadic intervals that fit inside \\([a, b)\\).\n\n\nTaking the Limit\nNotice that \\(\\frac{|J_k|}{2^k}\\) represents the total length of all dyadic intervals contained in \\([a, b)\\):\n\\[\n\\frac{|J_k|}{2^k} = \\sum_{j \\in J_k} \\text{length}(I_j)\n\\]\nAs \\(k \\to \\infty\\), these intervals cover \\([a, b)\\) with increasing precision, so we expect\n\\[\n\\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} = b - a\n\\]\nTherefore:\n\\[\\begin{align*}\n\\mathbb{P}[U \\in [a, b)] &= \\lim_{k \\to \\infty} \\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] \\\\\n&= \\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} \\\\\n&= b - a \\\\\n&= \\text{length}([a, b))\n\\end{align*}\\]\nas desired\n\n\nFrom Theory to Practice: Finite Bit Algorithms\nThe theoretical result above is beautiful, but it has a glaring practical issue: we cannot generate an infinite sequence of bits! In the real world, we need to work with a finite number of bits. Fortunately, our proof gives us a natural way to approximate the uniform distribution using only a finite number of bits.\nThe key insight is that after generating \\(N\\) bits, we’ve already determined which of the \\(2^N\\) dyadic intervals our value falls into. The remaining (ungenerated) bits would only refine our position within that interval, which has width \\(\\frac{1}{2^N}\\). For large \\(N\\), this interval is so small that the difference is negligible\nThis leads us to the following algorithm:\n\nAlgorithm 3\n\\(U \\gets 0\\)\nfor \\(i = 1\\) to \\(N\\) do\n\\(\\quad\\) Generate random bit \\(B_i\\)\n\\(\\quad\\) \\(U \\gets U + B_i \\cdot 2^{-i}\\)\nreturn \\(U\\)\n\nThis algorithm generates values of the form \\(\\frac{k}{2^N}\\) where \\(k \\in \\{0, 1, \\ldots, 2^N - 1\\}\\). In other words, it produces a discrete uniform distribution over \\(2^N\\) equally-spaced points in \\([0, 1]\\), rather than a truly continuous uniform distribution.\nLet \\(U_N\\) denote the output of Algorithm 3 and let \\(U_{\\text{true}}\\) denote a truly uniform random variable on \\([0, 1]\\). How far off is our approximation? Well the maximum distance between any generated value and its “true” counterpart is at most the granularity of our discretization: \\[\n\\max_{x \\in [0, 1]} |U_N - x| \\leq \\frac{1}{2^N}\n\\] So, if \\(N = 64\\), then we have: \\[\\begin{align*}\n\\frac{1}{2^{64}} &\\approx 5.42 \\times 10^{-20} \\\\\n\\end{align*}\\]\nThis means our approximation error is about \\(10^{-20}\\)! For all practical purposes, this is indistinguishable from a true uniform distribution. In fact, 64-bit floating point numbers (the standard in most programming languages) have a precision of about \\(10^{-16}\\), which is less precise than our sampling error.\n\n\n\n\n\n\nNotePractical Implementation\n\n\n\nIn practice, most programming languages use 64-bit floating point numbers for representing real numbers. Algorithm 3 with \\(N = 64\\) bits produces values that are uniformly distributed on the set of representable floating point numbers in \\([0, 1]\\), which is the best we can do given the finite precision of computer arithmetic.\n\n\nTherefore, Algorithm 3 with \\(N = 64\\) bits gives us an excellent practical algorithm for sampling (approximately) uniform real numbers in \\([0, 1]\\)."
  },
  {
    "objectID": "posts/sampling/index.html#section",
    "href": "posts/sampling/index.html#section",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "",
    "text": "First, let’s see if we can generate a uniformly random integer \\(N \\in \\{0, \\cdots, 2^N - 1\\}\\). That is."
  },
  {
    "objectID": "posts/sampling/index.html#hardware-assumptions",
    "href": "posts/sampling/index.html#hardware-assumptions",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "Hardware Assumptions",
    "text": "Hardware Assumptions\nOn most modern computers, one bit represents an atom of data or computation. So, if we want our computer to generate random samples, we would probably need it to be able to generate uniformly random bits. Let’s assume we have a black box machine that does exactly that.\n\n\n\n\n\n\nNoteNote\n\n\n\n\n\nAbove assumption is not an unrealistic one since we have hardware random bit generators which generate random bits from physical process that produce entropy.\n\n\n\nMore formally, let \\(B \\in \\{0, 1\\}\\) be a uniform random bit with \\[\\mathbb{P}[B = 0] = \\mathbb{P}[B = 1] = \\frac{1}{2}\\] and assume that we can sample from \\(B\\)."
  },
  {
    "objectID": "posts/sampling/index.html#note",
    "href": "posts/sampling/index.html#note",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "Note:",
    "text": "Note:\nThis proof is quite ri\n:::\nThe proof relies on a clever partitioning strategy. We’ll divide \\([0, 1]\\) into dyadic intervals—intervals whose endpoints are fractions with powers of 2 in the denominator.\nFor any \\(k \\in \\mathbb{N}\\), we partition \\([0, 1]\\) into \\(2^k\\) equal intervals: \\[\nI_j = \\left[\\frac{j}{2^k}, \\frac{j+1}{2^k}\\right) \\quad \\text{for } j = 0, 1, \\dots, 2^k - 1\n\\]\nEach interval has length \\(\\frac{1}{2^k}\\), and together they tile the entire unit interval.\n\n\nThe Key Insight: Bits Determine Intervals\n\n\n\n\n\n\nTipThe Crucial Observation\n\n\n\nThe first \\(k\\) bits \\((B_1, \\dots, B_k)\\) completely determine which dyadic interval \\(I_j\\) contains the value \\(U\\).\nSpecifically: \\[\nU \\in I_j = \\left[\\frac{j}{2^k}, \\frac{j+1}{2^k}\\right) \\iff \\sum_{i=1}^{k} B_i \\cdot 2^{-i} = \\frac{j}{2^k}\n\\]\n\n\nWhy does this work? Let’s break down the value of \\(U\\) into two parts:\n\\[\\begin{align*}\nU &= \\sum_{i=1}^{k} \\frac{B_i}{2^i} + \\sum_{i=k+1}^{\\infty} \\frac{B_i}{2^i} \\\\\n&= \\sum_{i=1}^{k} \\frac{B_i}{2^i} + \\frac{1}{2^k}\\sum_{i=1}^{\\infty} \\frac{B_{k+i}}{2^i}\n\\end{align*}\\]\nThe first sum represents the contribution from the first \\(k\\) bits—this gives us the starting point \\(\\frac{j}{2^k}\\) of some interval \\(I_j\\).\nThe second sum is just another binary expansion (with values in \\([0, 1)\\)), but scaled by \\(\\frac{1}{2^k}\\). Therefore: \\[\n0 \\leq \\frac{1}{2^k}\\sum_{i=1}^{\\infty} \\frac{B_{k+i}}{2^i} &lt; \\frac{1}{2^k}\n\\]\nThis means the remaining bits shift \\(U\\) somewhere within the interval \\(I_j\\), but cannot push it outside. The first \\(k\\) bits tell us which interval, while the remaining bits tell us where within that interval.\n\n\n\nComputing Probabilities for Dyadic Intervals\nNow we can calculate the probability that \\(U\\) lands in a specific dyadic interval \\(I_j\\):\n\\[\\begin{align*}\n\\mathbb{P}[U \\in I_j] &= \\mathbb{P}\\left[\\sum_{i=1}^{k} B_i \\cdot 2^{-i} = \\frac{j}{2^k}\\right] \\\\\n&= \\mathbb{P}[B_1 = b_1, B_2 = b_2, \\dots, B_k = b_k]\n\\end{align*}\\]\nwhere \\((b_1, \\dots, b_k)\\) is the binary representation of \\(j\\).\nSince the bits are independent and each has probability \\(\\frac{1}{2}\\):\n\\[\\begin{align*}\n\\mathbb{P}[U \\in I_j] &= \\prod_{i=1}^{k} \\mathbb{P}[B_i = b_i] \\\\\n&= \\prod_{i=1}^{k} \\frac{1}{2} \\\\\n&= \\frac{1}{2^k}\n\\end{align*}\\]\n\n\n\n\n\n\nImportantBeautiful Result\n\n\n\nEach dyadic interval \\(I_j\\) has probability \\(\\frac{1}{2^k}\\), which exactly equals its length!\n\n\n\n\n\nExtending to General Intervals\nFor a general interval \\([a, b] \\subseteq [0, 1]\\), we approximate it using dyadic intervals. Let \\(J_k\\) be the set of indices where \\(I_j \\subseteq [a, b)\\). Then:\n\\[\n[a, b) \\approx \\bigcup_{j \\in J_k} I_j\n\\]\nAs \\(k\\) increases, the dyadic intervals become finer, and this approximation improves.\nSince the dyadic intervals are disjoint:\n\\[\\begin{align*}\n\\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] &= \\sum_{j \\in J_k} \\mathbb{P}[U \\in I_j] \\\\\n&= \\sum_{j \\in J_k} \\frac{1}{2^k} \\\\\n&= \\frac{|J_k|}{2^k}\n\\end{align*}\\]\nwhere \\(|J_k|\\) is the number of dyadic intervals that fit inside \\([a, b)\\).\n\n\n\nTaking the Limit\nNotice that \\(\\frac{|J_k|}{2^k}\\) represents the total length of all dyadic intervals contained in \\([a, b)\\):\n\\[\n\\frac{|J_k|}{2^k} = |J_k| \\cdot 2^{-k} = \\sum_{j \\in J_k} \\text{length}(I_j)\n\\]\nAs \\(k \\to \\infty\\), these intervals tile \\([a, b)\\) with increasing precision, so:\n\\[\n\\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} = b - a\n\\]\nTherefore:\n\\[\\begin{align*}\n\\mathbb{P}[U \\in [a, b)] &= \\lim_{k \\to \\infty} \\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] \\\\\n&= \\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} \\\\\n&= b - a\n\\end{align*}\\]\n\n\n\n\n\n\nNoteTechnical Note\n\n\n\n\n\nThe step where we exchange the limit and probability uses the continuity of probability measures. A fully rigorous proof would also need to address measure-theoretic details and boundary effects, but we’ve captured the essential intuition here."
  },
  {
    "objectID": "posts/sampling/index.html#main-claim",
    "href": "posts/sampling/index.html#main-claim",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "Main Claim",
    "text": "Main Claim\nIf \\(B_1, B_2, B_3, \\dots\\) are independent uniform random bits, then \\[\nU = \\sum_{i=1}^{\\infty} \\frac{B_i}{2^i}\n\\] is uniformly distributed on \\([0, 1]\\)."
  },
  {
    "objectID": "posts/sampling/index.html#the-crucial-observation",
    "href": "posts/sampling/index.html#the-crucial-observation",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "The Crucial Observation",
    "text": "The Crucial Observation\nThe first \\(k\\) bits \\((B_1, \\dots, B_k)\\) completely determine which dyadic interval \\(I_j\\) contains the value \\(U\\).\nSpecifically: \\[\nU \\in I_j = \\left[\\frac{j}{2^k}, \\frac{j+1}{2^k}\\right) \\iff \\sum_{i=1}^{k} B_i \\cdot 2^{-i} = \\frac{j}{2^k}\n\\] :::\nWhy does this work? Let’s break down the value of \\(U\\) into two parts:\n\\[\\begin{align*}\nU &= \\sum_{i=1}^{k} \\frac{B_i}{2^i} + \\sum_{i=k+1}^{\\infty} \\frac{B_i}{2^i} \\\\\n&= \\sum_{i=1}^{k} \\frac{B_i}{2^i} + \\frac{1}{2^k}\\sum_{i=1}^{\\infty} \\frac{B_{k+i}}{2^i}\n\\end{align*}\\]\nThe first sum represents the contribution from the first \\(k\\) bits—this gives us the starting point \\(\\frac{j}{2^k}\\) of some interval \\(I_j\\).\nThe second sum is just another binary expansion (with values in \\([0, 1)\\)), but scaled by \\(\\frac{1}{2^k}\\). Therefore: \\[\n0 \\leq \\frac{1}{2^k}\\sum_{i=1}^{\\infty} \\frac{B_{k+i}}{2^i} &lt; \\frac{1}{2^k}\n\\]\nThis means the remaining bits shift \\(U\\) somewhere within the interval \\(I_j\\), but cannot push it outside. The first \\(k\\) bits tell us which interval, while the remaining bits tell us where within that interval.\n\n\nComputing Probabilities for Dyadic Intervals\nNow we can calculate the probability that \\(U\\) lands in a specific dyadic interval \\(I_j\\):\n\\[\\begin{align*}\n\\mathbb{P}[U \\in I_j] &= \\mathbb{P}\\left[\\sum_{i=1}^{k} B_i \\cdot 2^{-i} = \\frac{j}{2^k}\\right] \\\\\n&= \\mathbb{P}[B_1 = b_1, B_2 = b_2, \\dots, B_k = b_k]\n\\end{align*}\\]\nwhere \\((b_1, \\dots, b_k)\\) is the binary representation of \\(j\\).\nSince the bits are independent and each has probability \\(\\frac{1}{2}\\):\n\\[\\begin{align*}\n\\mathbb{P}[U \\in I_j] &= \\prod_{i=1}^{k} \\mathbb{P}[B_i = b_i] \\\\\n&= \\prod_{i=1}^{k} \\frac{1}{2} \\\\\n&= \\frac{1}{2^k}\n\\end{align*}\\]\n\n\n\n\n\n\nImportantBeautiful Result\n\n\n\nEach dyadic interval \\(I_j\\) has probability \\(\\frac{1}{2^k}\\), which exactly equals its length!\n\n\n\n\n\nExtending to General Intervals\nFor a general interval \\([a, b] \\subseteq [0, 1]\\), we approximate it using dyadic intervals. Let \\(J_k\\) be the set of indices where \\(I_j \\subseteq [a, b)\\). Then:\n\\[\n[a, b) \\approx \\bigcup_{j \\in J_k} I_j\n\\]\nAs \\(k\\) increases, the dyadic intervals become finer, and this approximation improves.\nSince the dyadic intervals are disjoint:\n\\[\\begin{align*}\n\\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] &= \\sum_{j \\in J_k} \\mathbb{P}[U \\in I_j] \\\\\n&= \\sum_{j \\in J_k} \\frac{1}{2^k} \\\\\n&= \\frac{|J_k|}{2^k}\n\\end{align*}\\]\nwhere \\(|J_k|\\) is the number of dyadic intervals that fit inside \\([a, b)\\).\n\n\n\nTaking the Limit\nNotice that \\(\\frac{|J_k|}{2^k}\\) represents the total length of all dyadic intervals contained in \\([a, b)\\):\n\\[\n\\frac{|J_k|}{2^k} = |J_k| \\cdot 2^{-k} = \\sum_{j \\in J_k} \\text{length}(I_j)\n\\]\nAs \\(k \\to \\infty\\), these intervals tile \\([a, b)\\) with increasing precision, so:\n\\[\n\\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} = b - a\n\\]\nTherefore:\n\\[\\begin{align*}\n\\mathbb{P}[U \\in [a, b)] &= \\lim_{k \\to \\infty} \\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] \\\\\n&= \\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} \\\\\n&= b - a\n\\end{align*}\\]\n\n\n\n\n\n\nNoteTechnical Note\n\n\n\n\n\nThe step where we exchange the limit and probability uses the continuity of probability measures. A fully rigorous proof would also need to address measure-theoretic details and boundary effects, but we’ve captured the essential intuition here."
  },
  {
    "objectID": "posts/sampling/index.html#note-rigorous-proof-1",
    "href": "posts/sampling/index.html#note-rigorous-proof-1",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "Note: rigorous proof",
    "text": "Note: rigorous proof\nThis discussion below assumes a little bit of real analysis background (we are working with real numbers after all). Feel free to skip this section if you are unfamiliar with the ideas below.\n:::\n\nComputing Probabilities for Dyadic Intervals\nNow we can calculate the probability that \\(U\\) lands in a specific dyadic interval \\(I_j\\):\n\\[\\begin{align*}\n\\mathbb{P}[U \\in I_j] &= \\mathbb{P}\\left[\\sum_{i=1}^{k} B_i \\cdot 2^{-i} = \\frac{j}{2^k}\\right] \\\\\n&= \\mathbb{P}[B_1 = b_1, B_2 = b_2, \\dots, B_k = b_k]\n\\end{align*}\\]\nwhere \\((b_1, \\dots, b_k)\\) is the binary representation of \\(j\\).\nSince the bits are independent and each has probability \\(\\frac{1}{2}\\):\n\\[\\begin{align*}\n\\mathbb{P}[U \\in I_j] &= \\prod_{i=1}^{k} \\mathbb{P}[B_i = b_i] \\\\\n&= \\prod_{i=1}^{k} \\frac{1}{2} \\\\\n&= \\frac{1}{2^k}\n\\end{align*}\\]\n\n\n\n\n\n\nImportantBeautiful Result\n\n\n\nEach dyadic interval \\(I_j\\) has probability \\(\\frac{1}{2^k}\\), which exactly equals its length!\n\n\n\n\n\nExtending to General Intervals\nFor a general interval \\([a, b] \\subseteq [0, 1]\\), we approximate it using dyadic intervals. Let \\(J_k\\) be the set of indices where \\(I_j \\subseteq [a, b)\\). Then:\n\\[\n[a, b) \\approx \\bigcup_{j \\in J_k} I_j\n\\]\nAs \\(k\\) increases, the dyadic intervals become finer, and this approximation improves.\nSince the dyadic intervals are disjoint:\n\\[\\begin{align*}\n\\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] &= \\sum_{j \\in J_k} \\mathbb{P}[U \\in I_j] \\\\\n&= \\sum_{j \\in J_k} \\frac{1}{2^k} \\\\\n&= \\frac{|J_k|}{2^k}\n\\end{align*}\\]\nwhere \\(|J_k|\\) is the number of dyadic intervals that fit inside \\([a, b)\\).\n\n\n\nTaking the Limit\nNotice that \\(\\frac{|J_k|}{2^k}\\) represents the total length of all dyadic intervals contained in \\([a, b)\\):\n\\[\n\\frac{|J_k|}{2^k} = |J_k| \\cdot 2^{-k} = \\sum_{j \\in J_k} \\text{length}(I_j)\n\\]\nAs \\(k \\to \\infty\\), these intervals tile \\([a, b)\\) with increasing precision, so:\n\\[\n\\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} = b - a\n\\]\nTherefore:\n\\[\\begin{align*}\n\\mathbb{P}[U \\in [a, b)] &= \\lim_{k \\to \\infty} \\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] \\\\\n&= \\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} \\\\\n&= b - a\n\\end{align*}\\]\n\n\n\n\n\n\nNoteTechnical Note\n\n\n\n\n\nThe step where we exchange the limit and probability uses the continuity of probability measures. A fully rigorous proof would also need to address measure-theoretic details and boundary effects, but we’ve captured the essential intuition here."
  },
  {
    "objectID": "posts/sampling/index.html#note-that",
    "href": "posts/sampling/index.html#note-that",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "Note that",
    "text": "Note that\n\nExtending to General Intervals\nFor a general interval \\([a, b] \\subseteq [0, 1]\\), we approximate it using dyadic intervals. Let \\(J_k\\) be the set of indices where \\(I_j \\subseteq [a, b)\\). Then:\n\\[\n[a, b) \\approx \\bigcup_{j \\in J_k} I_j\n\\]\nAs \\(k\\) increases, the dyadic intervals become finer, and this approximation improves.\nSince the dyadic intervals are disjoint:\n\\[\\begin{align*}\n\\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] &= \\sum_{j \\in J_k} \\mathbb{P}[U \\in I_j] \\\\\n&= \\sum_{j \\in J_k} \\frac{1}{2^k} \\\\\n&= \\frac{|J_k|}{2^k}\n\\end{align*}\\]\nwhere \\(|J_k|\\) is the number of dyadic intervals that fit inside \\([a, b)\\).\n\n\n\nTaking the Limit\nNotice that \\(\\frac{|J_k|}{2^k}\\) represents the total length of all dyadic intervals contained in \\([a, b)\\):\n\\[\n\\frac{|J_k|}{2^k} = |J_k| \\cdot 2^{-k} = \\sum_{j \\in J_k} \\text{length}(I_j)\n\\]\nAs \\(k \\to \\infty\\), these intervals tile \\([a, b)\\) with increasing precision, so:\n\\[\n\\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} = b - a\n\\]\nTherefore:\n\\[\\begin{align*}\n\\mathbb{P}[U \\in [a, b)] &= \\lim_{k \\to \\infty} \\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] \\\\\n&= \\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} \\\\\n&= b - a\n\\end{align*}\\]\n\n\n\n\n\n\nNoteTechnical Note\n\n\n\n\n\nThe step where we exchange the limit and probability uses the continuity of probability measures. A fully rigorous proof would also need to address measure-theoretic details and boundary effects, but we’ve captured the essential intuition here."
  },
  {
    "objectID": "posts/sampling/index.html#note-that-this-is-exactly-the-lenght-of-the-interval-i_j",
    "href": "posts/sampling/index.html#note-that-this-is-exactly-the-lenght-of-the-interval-i_j",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "Note that this is exactly the lenght of the interval \\(I_j\\)!",
    "text": "Note that this is exactly the lenght of the interval \\(I_j\\)!\n\nExtending to General Intervals\nFor a general interval \\([a, b] \\subseteq [0, 1]\\), we approximate it using dyadic intervals. Let \\(J_k\\) be the set of indices where \\(I_j \\subseteq [a, b)\\). Then:\n\\[\n[a, b) \\approx \\bigcup_{j \\in J_k} I_j\n\\]\nAs \\(k\\) increases, the dyadic intervals become finer, and this approximation improves.\nSince the dyadic intervals are disjoint:\n\\[\\begin{align*}\n\\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] &= \\sum_{j \\in J_k} \\mathbb{P}[U \\in I_j] \\\\\n&= \\sum_{j \\in J_k} \\frac{1}{2^k} \\\\\n&= \\frac{|J_k|}{2^k}\n\\end{align*}\\]\nwhere \\(|J_k|\\) is the number of dyadic intervals that fit inside \\([a, b)\\).\n\n\n\nTaking the Limit\nNotice that \\(\\frac{|J_k|}{2^k}\\) represents the total length of all dyadic intervals contained in \\([a, b)\\):\n\\[\n\\frac{|J_k|}{2^k} = |J_k| \\cdot 2^{-k} = \\sum_{j \\in J_k} \\text{length}(I_j)\n\\]\nAs \\(k \\to \\infty\\), these intervals tile \\([a, b)\\) with increasing precision, so:\n\\[\n\\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} = b - a\n\\]\nTherefore:\n\\[\\begin{align*}\n\\mathbb{P}[U \\in [a, b)] &= \\lim_{k \\to \\infty} \\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] \\\\\n&= \\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} \\\\\n&= b - a\n\\end{align*}\\]\n\n\n\n\n\n\nNoteTechnical Note\n\n\n\n\n\nThe step where we exchange the limit and probability uses the continuity of probability measures. A fully rigorous proof would also need to address measure-theoretic details and boundary effects, but we’ve captured the essential intuition here."
  },
  {
    "objectID": "posts/sampling/index.html#note-that-this-is-exactly-the-length-of-the-interval-i_j",
    "href": "posts/sampling/index.html#note-that-this-is-exactly-the-length-of-the-interval-i_j",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "Note that this is exactly the length of the interval \\(I_j\\)!",
    "text": "Note that this is exactly the length of the interval \\(I_j\\)!\n\nExtending to General Intervals\nFor a general interval \\([a, b] \\subseteq [0, 1]\\), we approximate it using dyadic intervals. Let \\(J_k\\) be the set of indices where \\(I_j \\subseteq [a, b)\\). Then:\n\\[\n[a, b) \\approx \\bigcup_{j \\in J_k} I_j\n\\]\nAs \\(k\\) increases, the dyadic intervals become finer, and this approximation improves.\nSince the dyadic intervals are disjoint:\n\\[\\begin{align*}\n\\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] &= \\sum_{j \\in J_k} \\mathbb{P}[U \\in I_j] \\\\\n&= \\sum_{j \\in J_k} \\frac{1}{2^k} \\\\\n&= \\frac{|J_k|}{2^k}\n\\end{align*}\\]\nwhere \\(|J_k|\\) is the number of dyadic intervals that fit inside \\([a, b)\\).\n\n\n\nTaking the Limit\nNotice that \\(\\frac{|J_k|}{2^k}\\) represents the total length of all dyadic intervals contained in \\([a, b)\\):\n\\[\n\\frac{|J_k|}{2^k} = |J_k| \\cdot 2^{-k} = \\sum_{j \\in J_k} \\text{length}(I_j)\n\\]\nAs \\(k \\to \\infty\\), these intervals tile \\([a, b)\\) with increasing precision, so:\n\\[\n\\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} = b - a\n\\]\nTherefore:\n\\[\\begin{align*}\n\\mathbb{P}[U \\in [a, b)] &= \\lim_{k \\to \\infty} \\mathbb{P}\\left[U \\in \\bigcup_{j \\in J_k} I_j\\right] \\\\\n&= \\lim_{k \\to \\infty} \\frac{|J_k|}{2^k} \\\\\n&= b - a\n\\end{align*}\\]\n\n\n\n\n\n\nNoteTechnical Note\n\n\n\n\n\nThe step where we exchange the limit and probability uses the continuity of probability measures. A fully rigorous proof would also need to address measure-theoretic details and boundary effects, but we’ve captured the essential intuition here."
  },
  {
    "objectID": "posts/sampling/index.html#arbitrary-probability-distribution",
    "href": "posts/sampling/index.html#arbitrary-probability-distribution",
    "title": "Algorithms for Sampling from a probability distribution",
    "section": "Arbitrary Probability Distribution",
    "text": "Arbitrary Probability Distribution\nThat was a lot of work! If it took so much effort just to sample from the uniform distribution, how can we possibly expect to come up with algorithms for complicated probability distributions? Well, it turns out that with not too much extra work we can sample from any arbitrary distribution \\(\\pi\\). More formally, lets say \\(\\pi\\) is a probability distribution on a finite state space \\(\\chi = \\{x_1, \\cdots x_n\\}\\). I want to generate an \\(X \\in \\chi\\) such that \\[\n\\mathbb{P}[X = x] = \\pi(x)\n\\] Now that we can sample from the uniform distribution on \\([0, 1]\\), let’s use that. We will use another clever partitioning technique, similar to what we did for proving the uniform distribution result.\nMore specifically, we divide the interval \\([0, 1]\\) into \\(N\\) consecutive segments. For each \\(i \\in \\{1, 2, \\ldots, N\\}\\), define segment \\(i\\) as: \\[\nS_i = \\left[\\sum_{j=1}^{i-1} \\pi(x_j), \\sum_{j=1}^{i} \\pi(x_j)\\right)\n\\] where by convention, \\(\\sum_{j=1}^{0} \\pi(x_j) = 0\\).\nObserve that segment \\(S_i\\) has length: \\[\n\\text{length}(S_i) = \\sum_{j=1}^{i} \\pi(x_j) - \\sum_{j=1}^{i-1} \\pi(x_j) = \\pi(x_i)\n\\]\nMoreover, these segments partition \\([0, 1]\\) since they are disjoint and: \\[\n\\bigcup_{i=1}^{N} S_i = [0, 1)\n\\] which follows from the fact that \\(\\sum_{i=1}^{N} \\pi(x_i) = 1\\) (since \\(\\pi\\) is a probability distribution). When we sample uniformly from \\([0, 1]\\), the probability of landing in segment \\(i\\) is exactly \\(\\pi(x_i)\\) (since the segment has length \\(\\pi(x_i)).\\) So if we return \\(x_i\\) whenever we land in segment \\(i\\), we get the desired distribution!\n\n\n\n\n\n\nTipIntuition\n\n\n\nThink of it like a dartboard: if you throw a dart uniformly at random on \\([0,1]\\), the probability of hitting a region is proportional to its length. By making segment \\(i\\) have length \\(\\pi(x_i)\\), we ensure the probability of hitting it matches our target probability.\n\n\nExample: Suppose \\(\\mathcal{X} = \\{x_1, x_2, x_3, x_4, x_5\\}\\) and \\(\\pi = (0.15, 0.25, 0.20, 0.30, 0.10)\\). We segment the \\([0, 1]\\) interval as shown below:\n\n\n\nSegmented [0, 1] Interval\n\n\nNow, we can sample a real number uniformly random, and return the segment that this number belongs to.\n\nFormalizing the Algorithm\nTo implement this efficiently, we use cumulative probabilities. Define: \\[\nF_i = \\sum_{j=1}^{i} \\pi(x_j) \\quad \\text{for } i = 1, 2, \\ldots, N\n\\] with \\(F_0 = 0\\). Note that \\(F_i\\) represents the cumulative probability up to and including \\(x_i\\), so segment \\(i\\) corresponds to the interval \\([F_{i-1}, F_i)\\).\nOur algorithm returns \\(x_i\\) when \\(U\\) falls in the interval \\([F_{i-1}, F_i)\\):\n\nAlgorithm 4\nPreprocessing:\nCompute cumulative probabilities: \\(F_0 \\gets 0\\)\nfor \\(i = 1\\) to \\(N\\) do\n\\(\\quad\\) \\(F_i \\gets F_{i-1} + \\pi(x_i)\\)\nSampling:\nGenerate \\(U \\sim \\text{Uniform}[0, 1]\\) using Algorithm 3\nfor \\(i = 1\\) to \\(N\\) do\n\\(\\quad\\) if \\(F_{i-1} \\leq U &lt; F_i\\) then\n\\(\\quad\\quad\\) return \\(x_i\\)\n\nLet’s verify that this algorithm produces the correct distribution. For any \\(x_i \\in \\mathcal{X}\\):\n\\[\\begin{align*}\n\\mathbb{P}[\\text{output} = x_i] &= \\mathbb{P}[F_{i-1} \\leq U &lt; F_i] \\\\\n&= F_i - F_{i-1} \\tag{$U$ is uniform on $[0,1]$} \\\\\n&= \\left(\\sum_{j=1}^{i} \\pi(x_j)\\right) - \\left(\\sum_{j=1}^{i-1} \\pi(x_j)\\right) \\\\\n&= \\pi(x_i)\n\\end{align*}\\]\nThe second equality uses the fact that for a uniform random variable \\(U\\) on \\([0,1]\\), we have \\(\\mathbb{P}[a \\leq U &lt; b] = b - a\\). Therefore, our algorithm produces samples distributed according to \\(\\pi\\). Problem solved!\n\n\n\n\n\n\nNoteComputational Complexity\n\n\n\nThe preprocessing step takes \\(O(N)\\) time to compute cumulative probabilities. Each sample then requires \\(O(N)\\) time in the worst case to find which segment \\(U\\) falls into (via linear search). This can be improved to \\(O(\\log N)\\) per sample using binary search, since the cumulative probabilities \\(F_i\\) are sorted."
  }
]